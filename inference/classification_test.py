import os
from time import time
import numpy as np
import cv2
import onnxruntime
from collections import Counter
import logging
import json
import shutil
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

# from inference.classification_confusion import Benchmark

class Benchmark():
    def __init__(self, csv_filename, test_path=None):
        """
        Class initialization for Benchmarking
        :param csv_filename: csv filename to load or to save
        """
        self.csv_filename = csv_filename
        self.test_path = test_path
        if not os.path.isfile(csv_filename):
            self.df = pd.DataFrame()
        else:
            self.df = pd.read_csv(csv_filename, index_col=0)


    def _pandas_confusion(self):
        """
        Function for creating confusion matrix using pandas and watching in notebooks
        :return: confusion matrix of given true labels and predicted labels
        """
        self.confusion_matrix = pd.crosstab(self.df['true_label'], self.df['predict_label'], rownames=['Actual'],
                                            colnames=['Predicted'])


    def load_class_names(self, namesfile):
        """
        Function to load classes names from directory
        :param namesfile: txt or names files as class names
        :return: list of class names
        """
        class_names = []
        with open(namesfile, 'r') as fp:
            lines = fp.readlines()
        for line in lines:
            line = line.rstrip()
            class_names.append(line)
        return class_names


    def append_true_csv(self,save=False):
        """
        Function to append target labels in true_label column
        :param path: path to image directory
        :return: labels as a list
        """
        for path,_, filenames in os.walk(self.test_path):
            for filename in filenames:
                text = path.split("/")
                self.df = self.df.append({"image_name": filename, "true_label": text[-1]}, ignore_index=True)
                self.labels = self.df["true_label"].unique()
        if save:
            self.csv_save()
        return self.labels


    def append_predict_csv(self, filename, predict_value):
        """
        Function to append predicted output in csv
        :param filename: image name as filename
        :param predict_value: output generated by the model
        :return: None
        """
        index_value = np.where(self.df["image_name"] == filename)
        if "predict_label" not in self.df.columns:
            self.df.insert(2, "predict_label", predict_value)
        if len(index_value[0]) != 0:
            self.df.loc[index_value[0][0], "predict_label"] = predict_value
        else:
            print("cannot insert")

    def get_statistics(self):
        """
        Function to get True postives,False Negatives and Accuracy
        :return: Returns value of TP,FN,Accuracy
        """
        TP = 0
        true_label = self.df["true_label"]
        predict_label = self.df["predict_label"]
        for i, j in enumerate(confusion_matrix(true_label, predict_label)):
            TP += j[i]
        FN = len(true_label) - TP
        Accuracy = TP / len(true_label)
        return TP, FN, Accuracy

    def image_save(self, img_save_path):
        """
        Function for watching colourful confusion matrix in notebooks only
        :return: None
        """
        self._pandas_confusion()
        print(self.confusion_matrix)
        plt.figure(facecolor='w', edgecolor='k', figsize=(10,10))
        sns.heatmap(self.confusion_matrix, annot=True, cmap='viridis', cbar=False, fmt='g')
        plt.savefig(img_save_path)


    def csv_save(self):
        self.df.to_csv("{}".format(self.csv_filename))


class ClassifierEvaluation():
    def __init__(self, session_path, test_path, logger, model_name):
        self.session_path = session_path
        self.test_path = test_path
        self.logger = logger
        self.weights_name = model_name + '.onnx'
        self.weights_path = os.path.join(self.session_path, self.weights_name)
        self.log_path = os.path.join(self.session_path, 'predictions.csv')
        self.confusion_matrix_path = os.path.join(self.session_path, 'confusion_matrix.png')
        self.labels = self.__get_classes()
        self.session = onnxruntime.InferenceSession(self.weights_path)
        self.bench = Benchmark(self.log_path, self.test_path)
        self.bench.append_true_csv(save=self)


    def __get_classes(self):
        classes = sorted(os.listdir(self.test_path))
        classes_dict = {ind:class_ for ind,class_ in enumerate(classes)}
        return classes_dict


    def pad_image(self, image, size=(256,256)):
        h,w,c = image.shape
        pad_l = pad_r = int((size[1]-w)/2)
        pad_t = pad_b = int((size[0]-h)/2)
        img = cv2.copyMakeBorder(image.copy(), pad_t, pad_b, pad_l, pad_r, cv2.BORDER_CONSTANT)
        img = cv2.resize(img, size)
        return img


    def predict(self, image, pad=True):
        img_path = image
        img = cv2.imread(img_path)
        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
        if pad:
            img = self.pad_image(img)
        else:
            img = cv2.resize(img, (256,256))

        data = img.astype(np.float32) / 255.0
        data -= np.array([0.485, 0.456, 0.406],dtype=np.float32)
        data /=  np.array([0.229, 0.224, 0.225],dtype=np.float32)
        data=np.transpose(data, (2, 0, 1))
        data = np.expand_dims(data, axis= 0)
        input_name = self.session.get_inputs()[0].name
        feed = {input_name: data}
        pred_onnx = self.session.run(None, feed)
        return pred_onnx


    def test_from_image(image, pad=True):
        preds = predict(image)
        label = [ self.labels[np.argmax(pred)] for pred in preds ]
        return  label


    def test_from_directory(self, directory, class_label=None, pad=True):
        predictions = []
        img_predictions = {}
        accuracy = None
        images = os.listdir(directory)

        for i, img_name in enumerate(images):
            img_path = os.path.join(directory, img_name)
            img = cv2.imread(img_path)  #reads image into numpy array of size (height,width,no_of_color_channels)
            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)  #converts from BGR to RGB colorspace
            if pad:
                img = self.pad_image(img)    #pads the image to get desired dimension. In our case (256,256,3)
            else:
                img = cv2.resize(img, (256,256))

            data = img.astype(np.float32)/255.0 #normalize data by 255
            data -= np.array([0.485, 0.456, 0.406],dtype=np.float32)
            data /=  np.array([0.229, 0.224, 0.225],dtype=np.float32)
            data=np.transpose(data, (2, 0, 1))
            data = np.expand_dims(data, axis=0) #expands the outer dimension of the array. Now it becomes (1,256,256,3)
            input_name = self.session.get_inputs()[0].name
            feed = {input_name:data} #prepares input for the model
            pred_onnx = self.session.run(None, feed)    #run the inference on input data

            # get index of a maximum value in the array. here we get array of 15 outputs. So, we extract index of the array
            # that contains maximum value and then get the label name for that index
            label = [ self.labels[np.argmax(pred)] for pred in pred_onnx ]

            self.bench.append_predict_csv(img_name, label[0])

            predictions.extend(label)
            img_predictions[img_name] = label[0]

        self.bench.csv_save()

        if class_label is not None:
            preds = dict(Counter(predictions))
            try:
                accuracy = preds[class_label] / float(len(images))
            except:
                accuracy = 0

        try:
            TP = preds[class_label]
        except KeyError:
            preds[class_label] = 0
        return img_predictions, preds, accuracy


    def evaluate(self):
        all_preds = {}
        all_TP = 0
        all_FN = 0

        for class_ in os.listdir(self.test_path):
            predictions, count, accuracy = self.test_from_directory(os.path.join(self.test_path, class_), class_)
            all_preds[class_] = count

            TP = count[class_]

            FN = len(os.listdir(os.path.join(self.test_path, class_)))-count[class_]
            all_TP += TP
            all_FN += FN
            print("\nClass: {}\n\tTP: {},\tFN: {}, \tAccuracy: {}\nCounts: {}\n".format(
                class_, TP, FN, accuracy, json.dumps(count)))
            # self.logger.info("\nClass: {}\n\tTP: {},\tFN: {}, \tAccuracy: {}\nCounts: {}\n".format(
            #     class_, TP, FN, accuracy, json.dumps(count)))
        
        print("All TP: {},\tAll FN: {},\tOverall Accuracy: {}\n".format(
            all_TP, all_FN, all_TP/(all_TP+all_FN)))
        # self.logger.info("All TP: {},\tAll FN: {},\tOverall Accuracy: {}\n".format(
        #     all_TP, all_FN, all_TP/(all_TP+all_FN)))

        self.bench.image_save(self.confusion_matrix_path)
        # self.logger.info("Evaluation complete.")