import pandas as pd
from sklearn.metrics import confusion_matrix
import numpy as np
import os
import seaborn as sns
import matplotlib.pyplot as plt


class Benchmark():
    def __init__(self, csv_filename, test_path=None):
        """
        Class initialization for Benchmarking
        :param csv_filename: csv filename to load or to save
        """
        self.csv_filename = csv_filename
        self.test_path = test_path
        if not os.path.isfile(csv_filename):
            self.df = pd.DataFrame()
        else:
            self.df = pd.read_csv(csv_filename, index_col=0)


    def _pandas_confusion(self):
        """
        Function for creating confusion matrix using pandas and watching in notebooks
        :return: confusion matrix of given true labels and predicted labels
        """
        self.confusion_matrix = pd.crosstab(self.df['true_label'], self.df['predict_label'], rownames=['Actual'],
                                            colnames=['Predicted'])


    def load_class_names(self, namesfile):
        """
        Function to load classes names from directory
        :param namesfile: txt or names files as class names
        :return: list of class names
        """
        class_names = []
        with open(namesfile, 'r') as fp:
            lines = fp.readlines()
        for line in lines:
            line = line.rstrip()
            class_names.append(line)
        return class_names


    def append_true_csv(self,save=False):
        """
        Function to append target labels in true_label column
        :param path: path to image directory
        :return: labels as a list
        """
        for path,_, filenames in os.walk(self.test_path):
            for filename in filenames:
                text = path.split("/")
                self.df = self.df.append({"image_name": filename, "true_label": text[-1]}, ignore_index=True)
                self.labels = self.df["true_label"].unique()
        if save:
            self.csv_save()
        return self.labels


    def append_predict_csv(self, filename, predict_value):
        """
        Function to append predicted output in csv
        :param filename: image name as filename
        :param predict_value: output generated by the model
        :return: None
        """
        index_value = np.where(self.df["image_name"] == filename)
        if "predict_label" not in self.df.columns:
            self.df.insert(2, "predict_label", predict_value)
        if len(index_value[0]) != 0:
            self.df.loc[index_value[0][0], "predict_label"] = predict_value
        else:
            print("cannot insert")

    def get_statistics(self):
        """
        Function to get True postives,False Negatives and Accuracy
        :return: Returns value of TP,FN,Accuracy
        """
        TP = 0
        true_label = self.df["true_label"]
        predict_label = self.df["predict_label"]
        for i, j in enumerate(confusion_matrix(true_label, predict_label)):
            TP += j[i]
        FN = len(true_label) - TP
        Accuracy = TP / len(true_label)
        return TP, FN, Accuracy

    def image_save(self, img_save_path):
        """
        Function for watching colourful confusion matrix in notebooks only
        :return: None
        """
        self._pandas_confusion()
        print(self.confusion_matrix)
        plt.figure(facecolor='w', edgecolor='k', figsize=(10,10))
        sns.heatmap(self.confusion_matrix, annot=True, cmap='viridis', cbar=False, fmt='g')
        plt.savefig(img_save_path)


    def csv_save(self):
        self.df.to_csv("{}".format(self.csv_filename))


if __name__ == '__main__':
    bench = Benchmark('densenet_20c_266_039.csv')
    bench.image_save()